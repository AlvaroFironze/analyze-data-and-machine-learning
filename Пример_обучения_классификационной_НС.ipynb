{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6194e927",
   "metadata": {
    "cellId": "f33g5a6iipq8wlhgha02"
   },
   "outputs": [],
   "source": [
    "# Импорт зависимостей\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Activation, Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0996ddaa",
   "metadata": {
    "cellId": "3nspu9k2o1lm2szl6r0nm8"
   },
   "outputs": [],
   "source": [
    "#Путь к папкам с данными для обучения\n",
    "\"\"\"\n",
    "В папках (train, val) должны находиться папки, имя которых - название класса\n",
    "пример:\n",
    "/train\n",
    "    - /cats\n",
    "    - /dogs\n",
    "/val\n",
    "    - /cats\n",
    "    - /dogs\n",
    "Количество данных в обучающей выборке может быть неравномерным\n",
    "В валидационной выборке как правило делают равномерное распределение (к примеру,по 50 снимков на класс)\n",
    "\"\"\"\n",
    "train_dir = \"/train\"\n",
    "val_dir = \"/val\"\n",
    "\n",
    "# Размер изображения для вохдного тензора нейросети (см. документацию по НС https://www.tensorflow.org/api_docs/python/tf/keras/applications)\n",
    "\"\"\"Если при обучении используются предобученные веса (imagenet...), то размер входного тензора должен соответсвовать весам\"\"\"\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "# Входной тензор\n",
    "input_shape = (img_width, img_height,3)\n",
    "\n",
    "# Количество классов для обучения\n",
    "num_classes = 3\n",
    "\n",
    "# Количество эпох обучения\n",
    "epochs = 50\n",
    "\n",
    "# Количество изображений, которые будут подаваться НС при одной итерации обучения\n",
    "batch_size = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8f089e3c",
   "metadata": {
    "cellId": "ul8u0ei553yjd2dwfi0f"
   },
   "outputs": [],
   "source": [
    "# В качестве основной модели загружаем модель MobileNet с предобученными весами imagenet\n",
    "base_model = tf.keras.applications.MobileNet(\n",
    "    input_shape=(img_width, img_height, 3),\n",
    "    include_top=False, #True\n",
    "    weights='imagenet',\n",
    "    classes=num_classes,\n",
    ")\n",
    "# Включаем переобучение основной модели\n",
    "base_model.trainable = True\n",
    "# Добавляем слои полносвязного слоя в модель\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Dropout(0.1))\n",
    "model.add(GlobalAveragePooling2D(name='global_average_pooling2d'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(num_classes, activation='softmax', name='predictions'))\n",
    "\n",
    "# Пример с другим вариантом полносвязного слоя\n",
    "# model.add(base_model)\n",
    "# model.add(tf.keras.layers.Flatten())\n",
    "# model.add(tf.keras.layers.Dropout(0.2))\n",
    "# model.add(tf.keras.layers.Dense(num_classes, activation='softmax', name='predictions'))\n",
    "\n",
    "# model.layers[0].trainable = False\n",
    "# Ещё раз включаем переобучение для всех слоёв НС\n",
    "for cnn_block_layer in model.layers[0].layers:\n",
    "   cnn_block_layer.trainable = True\n",
    "model.layers[0].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8e6046c2",
   "metadata": {
    "cellId": "1i9ihj2x70aahxfiqh1k7c"
   },
   "outputs": [],
   "source": [
    "# Скорость обучения НС \n",
    "\"\"\"\n",
    "Если несколько эпох подряд на старте обучения получаются одинаковые значения точности примерно равные доле от 100/количество классов\n",
    "Например: при 3 классах точность держится в районе 0.33\n",
    "https://machinelearningmastery.com/using-learning-rate-schedules-deep-learning-models-python-keras/\n",
    "\"\"\"\n",
    "learning_rate = 0.00001\n",
    "# Параметры специфичные для оптимизатора SGD \n",
    "decay_rate = learning_rate / epochs\n",
    "momentum = 0.8\n",
    "# Другие оптимизаторы https://keras.io/api/optimizers/\n",
    "sgd = SGD(learning_rate=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "# Компиляция модели\n",
    "\"\"\"\n",
    "Функции потерь: https://keras.io/api/losses/\n",
    "Метрики точности: https://keras.io/api/metrics/\n",
    "\"\"\"\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd, \n",
    "              metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5f83c227",
   "metadata": {
    "cellId": "uw2wjxligi63pbcf5h4jm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenet_1.00_224 (Function (None, 7, 7, 1024)        3228864   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 3,231,939\n",
      "Trainable params: 3,210,051\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Вывод структуры полученной модели\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "97b69e03",
   "metadata": {
    "cellId": "k2h4ekpelgd4tvyhrnqq34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3311 images belonging to 3 classes.\n",
      "Found 150 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Генератор данных \n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "datagen = ImageDataGenerator(rescale=1. / 255, \n",
    "    validation_split=0,\n",
    "    vertical_flip=True,\n",
    "    horizontal_flip=False,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    seed=1\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    seed=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "75a60d8e",
   "metadata": {
    "cellId": "rvol2ko73kd7t76ue3t2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train generator: 3311 pics\n",
      "Val generator: 150 pics\n",
      "Epochs: 50\n",
      "Batch_size: 18\n",
      "\n",
      "{0: 3.8057471264367817, 1: 1.7005649717514124, 2: 0.4652894884766723}\n",
      "Epoch 1/50\n",
      "183/183 [==============================] - 99s 529ms/step - loss: 1.3115 - categorical_accuracy: 0.3808 - val_loss: 1.3369 - val_categorical_accuracy: 0.3472\n",
      "\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.34722, saving model to chkpt/N_H_L_MobileNet/01_acc_0.35.h5\n",
      "Epoch 2/50\n",
      "111/183 [=================>............] - ETA: 37s - loss: 1.2141 - categorical_accuracy: 0.3886"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-f5c348974168>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# https://towardsdatascience.com/learning-rate-schedules-and-adaptive-learning-rate-methods-for-deep-learning-2c8f433990d1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m histoty = model.fit(\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Директория, в которую будут сохраняться лучшие эпохи обучения\n",
    "cpt_dir = \"chkpt/N_H_L_MobileNet\"  \n",
    "# Балансировка весов в обучающей выборке при помощи пакета sklearn\n",
    "\"\"\"\n",
    "Балансировка весов помогает избежать \"перевеса\" НС в сторону одного из классов при неравномерном распределении количества данных в разных классах\n",
    "\"\"\"\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(train_generator.classes),\n",
    "                                                 train_generator.classes)\n",
    "# Приведение к необходимому формату\n",
    "class_weights = {i : class_weights[i] for i in range(len(class_weights))}\n",
    "print(class_weights)\n",
    "\n",
    "\"\"\"Запуск обучения НС\"\"\"\n",
    "histoty = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator.filenames) // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator.filenames) // batch_size,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[\n",
    "          #Сохраняем лучшую эпоху обучения\n",
    "          ModelCheckpoint(cpt_dir + '/{epoch:02d}_acc_{val_categorical_accuracy:.2f}.h5', monitor='val_categorical_accuracy', verbose=True, save_best_only=True), \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b19825e1",
   "metadata": {
    "cellId": "3zf7m1ccwvu3tegukipzwj",
    "execution_id": "cff009c3-5a80-46ec-99cd-4b8c3386d07b"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001f5ee7",
   "metadata": {
    "cellId": "80zuqvcpdn8uk9eokhmo5g"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "8b186155-e94d-4a95-8b61-bb125e5b1cec",
  "notebookPath": "ForStudents.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
